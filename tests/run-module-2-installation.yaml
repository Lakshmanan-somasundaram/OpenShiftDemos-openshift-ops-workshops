---
- name: Tests for verifying the OpenShift installation
  hosts: masters
  tags:
    - deployment_verify
  tasks:
    # variable file is autogenerated during cloudformation provisioning
    - include_vars: /opt/lab/environment.yml

    - set_fact:
        api_health_url: "{{ API_HEALTH_URL }}"
        ocp_routing_suffix: "{{ OCP_ROUTING_SUFFIX }}"

    - name: Check that oc client is v3.10.14
      command: oc version
      register: version
      changed_when: false

    - assert:
        that:
          - "'v3.10.14' in version.stdout"
          - "'v1.10.0+b81c8f8' in version.stdout"

    - name: Checking status of all the nodes to be 'Ready'
      command: oc get -o jsonpath='{.status.conditions[?(@.reason=="KubeletReady")].type}' node {{ item }}
      with_items:
        - "{{ groups.nodes }}"
      register: status_of_node
      changed_when: false

    - assert:
        that:
          - "'Ready' in item.stdout"
      with_items:
        - "{{ status_of_node.results }}"

    - name: Validate the public address
      uri:
        url: "{{ api_health_url }}"
        validate_certs: False
        status_code: 200
        method: GET
      changed_when: false

- name: Actions to automate user actions after OpenShift installation
  hosts: masters
  tags:
    - deployment_simulate
  tasks:
    # variable file is autogenerated during cloudformation provisioning
    - include_vars: /opt/lab/environment.yml

    - name: login to OCP using system:admin
      shell: oc login -u system:admin -n default
      register: login
      changed_when: false

    - assert:
        that:
          - "'Logged into \"https://master.internal.aws.testdrive.openshift.com:443\" as \"system:admin\" using existing credentials.' in login.stdout"
          - "'project \"default\".' in login.stdout"

    - name: list all nodes
      shell: oc get nodes
      register: nodes
      changed_when: false

    - set_fact:
        infra_fqdn: "{{ INFRA_INTERNAL_FQDN }}"
        master_fqdn: "{{ MASTER_INTERNAL_FQDN }}"
        node1_fqdn: "{{ NODE1_INTERNAL_FQDN }}"
        node2_fqdn: "{{ NODE2_INTERNAL_FQDN }}"
        node3_fqdn: "{{ NODE3_INTERNAL_FQDN }}"

    - name: ensure nodes are present
      assert:
        that:
          - "infra_fqdn in nodes.stdout"
          - "master_fqdn in nodes.stdout"
          - "node1_fqdn in nodes.stdout"
          - "node2_fqdn in nodes.stdout"
          - "node3_fqdn in nodes.stdout"

    - name: check that there is a prometheus statefulset
      shell: oc get statefulset prometheus -n openshift-metrics

    - name: check that prometheus components are running
      shell: oc get pod prometheus-0 --template='{.status.containerStatuses[?(@.name=="{{ item|quote }}")].ready}' -o jsonpath -n openshift-metrics
      register: prometheus_status_out
      failed_when: "'true' not in prometheus_status_out.stdout"
      with_items:
        - "prom-proxy"
        - "prometheus"
        - "alerts-proxy"
        - "alert-buffer"
        - "alertmanager-proxy"
        - "alertmanager"

    - name: check for prometheus-related routes
      shell: oc get route {{ item }} -n openshift-metrics
      with_items:
        - "alertmanager"
        - "alerts"
        - "prometheus"

    # there should be 5 nodes, including master, at this point, with exporters
    - name: check for 5 prometheus node exporters
      shell: oc get daemonset prometheus-node-exporter -o jsonpath --template='{.status.numberReady}' -n openshift-metrics
      register: prometheus_exporter_out
      failed_when: "'5' not in prometheus_exporter_out.stdout"

    - set_fact:
        cns_namespace: "{{ CNS_NAMESPACE }}"
        ocp_routing_suffix: "{{ OCP_ROUTING_SUFFIX }}"
        heketi_admin_pw: "{{ HEKETI_ADMIN_PW }}"

    - name: list heketi cluster
      shell: heketi-cli cluster list
      register: heketi
      changed_when: false
      environment:
        HEKETI_CLI_SERVER: http://heketi-storage-{{ cns_namespace }}.{{ ocp_routing_suffix }}
        HEKETI_CLI_USER: admin
        HEKETI_CLI_KEY: "{{ heketi_admin_pw }}"

    - name: ensure there is a CNS cluster with file and block enabled
      assert:
        that:
          - "'[file][block]' in heketi.stdout"

    - name: query heketi topology
      shell: heketi-cli topology info
      changed_when: false
      environment:
        HEKETI_CLI_SERVER: http://heketi-storage-{{ cns_namespace }}.{{ ocp_routing_suffix }}
        HEKETI_CLI_USER: admin
        HEKETI_CLI_KEY: "{{ heketi_admin_pw }}"
